# 8장 가상메모리

## 1. 개요 
   - 프로그램 실행을 위해서 프로그램에 필요한 부분이 메모리에 올라와 있어야 함, 그 프로세스의 주소 공간 전체가 메모리에 올라와 있어야 하는 것은 아님. 

   - **따라서 운영체제는 CPU에서 당장 수행해야 할 부분만을 메모리에 올려놓고 그렇지 않은 부분은 디스크의 스왑 영역에 내려놓았다가 다시 필요해지면 메모리에 올라간 부분과 교체하는 방식 사용**

     


## 2. 요구 페이징 (demand paging)
   - **요구 페이징** : 프로그램 실행 시 프로세스를 구성하는 모든 페이지를 한꺼번에 메모리에 올리는 것이 아닌 **당장 사용될 페이지만을 올리는 방식**
     
     - 메모리 사용량 감소
     - 입출력 오버헤드 감소
     - 응답시간 단축
     - 더 많은 사용자 수용 (더 많은 사용자가 동시에 메모리에 올라갈 수 있음)
     - 프로그램이 물리적 메모리의 용량 제약을 벗어난다 : 프로그램을 구성하는 일부 페이지만 적재하기 때문에 물리적 메모리의 용량보다 큰 프로그램도 실행할 수 있게 되기 때문
     
   - **유효 - 무효 비트** : 특정 프로세스를 구성하는 페이지 중 어떤 페이지가 메모리에 존재하고 어떤 페이지가 존재하지 않는지를 판별하기 위한 방식 
     - 프로세스 실행 전 : 모든 페이지가 무효값
     - 프로세스 실행 중 : 메모리에 적재된 페이지의 값 유효, 해당 페이지가 스왑영역으로 갈 경우 무효값
     - **페이지 부재 (page fault)** : 유효-무효 비트가 무효로 세팅되어 있는 경우 - 페이지가 현재 메모리에 없는 경우 or 그 페이지가 속한 주소 영역을 프로세스가 사용하지 않는 경우
      ![](8장 가상메모리.assets/image-20210629102629505-1624929991495.png)



   1. 요구 페이징의 부재 처리 

      1. CPU가 무효 페이지에 접근하면 MMU (주소 변환을 담당하는 하드웨어)가 페이지 부재 트랩을 발생 시킴

      2. CPU가 커널 모드로 전환되고 page fault handler가 실행됨

      3. 해당 페이지에 대한 접근이 적법한지 확인
         1. 적법하지 않을 경우 : 강제 종료
         2. 적법할 경우 : 디스크에서 해당 페이지를 메모리로 옮김, 비어있는 페이지가 없는 경우 메모리에 올라와있는 페이지 중 하나를 디스크로 쫓아냄(스왑 아웃)
         
         ![image-20210629103225734](8장 가상메모리.assets/image-20210629103225734-1624930347090.png)
         
         ​	![image-20210629105513989](8장 가상메모리.assets/image-20210629105513989-1624931717669.png

   2. 요구 페이징의 성능
      - 페이지 부재가 적게 발생할 수록 요구 페이징의 성능은 향상 (페이지 부재 발생 시 오버헤드가 발생하기 때문)

      - 요구 페이징의 성능은 요청한 페이지를 참조하는데 걸리는 유효 접근 시간으로 측정

        - 유효 접근시간(effective access time)

          = (1 - P) x 메모리 접근 시간 + P x (페이지 부재 발생 처리 오버헤드 + 메모리에 빈 프레임이 없는 경우 스왑 아웃 오버헤드 + 요청된 페이지의 스왑 인 오버헤드 + 프로세스의 재시작 오버헤드)

        - P : 페이지 부재 발생비율 (page fault rare) 0 <= P < 1
          - P = 0 : 페이지 부재가 한번도 일어나지 않은 경우 
          - P = 1 : 모든 참조 요청에서 페이지 부재가 발생한 경우 



## 3. 페이지 교체 (Page Replacement)

- 어떤 페이지를 쫓아낼지 결정하여 victim이 결정되면 디스크로 쫓아내는 작업 
- 교체 알고리즘 : 어떤 페이지를 쫓아낼지 결정하는 알고리즘, 페이지 부재율을 최소화하는 것이 목표이므로 미래에 참조될 가능성이 가장 적은 페이지를 선택해서 내쫓아야한다.

![image-20210629105600326](8장 가상메모리.assets/image-20210629105600326.png)



1. 최적 페이지 교체 (Optimal Algorithm)

   - 빌레디의 최적 알고리즘 : 가장 먼 미래에 참조될 페이지를 선정하여 쫓아내는 방식
   - 다른 어떠한 알고리즘보다 낮은 페이지 부재율을 보장, 다른 알고리즘의 성능에 대한 상한선을 제공
   - 오프라인 알고리즘 : 미래에 어떤 페이지가 어떤 순서로 참조될지 미리 알고 있다는 전제가 필요, 따라서 온라인으로 사용 불가 

   ![image-20210629142927144](8장 가상메모리.assets/image-20210629142927144-1624944568916.png)

2. 선입선출 알고리즘 (First In First Out)

   - 메모리에 가장 먼저 올라온 페이지를 가장 먼저 내쫓음

   - 페이지의 향후 참조 가능성을 고려하지 않기 때문에 비효율적

   - FIFO 이상 현상 (FIFO Anomaly) : 메모리를 증가시켰음에도 오히려 페이지 부재율이 높아지는 현상 (미래의 참조 가능성을 고려하지 않기 때문에 발생)

     ![image-20210629144101243](8장 가상메모리.assets/image-20210629144101243.png)

3. LRU 알고리즘 (Least Recently Used)

   - 시간지역성 (temporal locality) : 최근에 참조된 페이지가 가까운 미래에 다시 참조될 가능성이 높은 성질

   - LRU는 시간지역성을 감안하여 페이지 교체 시 가장 오래전에 참조된 페이지를 쫓아낸다, 즉 마지막 참조 시점이 가장 오래된 페이지를 교체한다

     ![image-20210629144432666](8장 가상메모리.assets/image-20210629144432666-1624945474423.png)

4. LFU 알고리즘 (Least Frequently Used)

   - 페이지의 참조 횟수로 교체시킬 페이지를 결정, 즉 과거의 참조횟수가 가장 적었던 페이지를 쫓아낸다
   - 성능 향상을 위해 참조 횟수가 동률인 페이지 중에 참조 시점이 더 오래된 페이지를 쫓아내는 방식이 있다

   1. Incache-LFU : 페이지가 물리적 메모리에 올라온 후부터의 참조 횟수를 계산하는 방식, 페이지가 메모리에서 쫓겨났다가 돌아오면 참조 횟수는 1로 초기화된다.
   2. Perfect-LFU : 페이지가 쫓겨났다가 다시 돌아온 경우 누적하여 계산하는 방식, 메모리에서 쫓겨난 페이지의 참조기록까지 보관해야 하므로 오버헤드가 상대적으로 높다.

5. LRU 알고리즘 vs LFU 알고리즘

   |                         |        LRU 알고리즘         |                LFU 알고리즘                |
   | :---------------------: | :-------------------------: | :----------------------------------------: |
   |        참조기록         | 직전에 참조된 시점만을 반영 | 오랜 시간 동안의 참조 기록 반영 (오버헤드) |
   |          구현           |         비교적 쉬움         |                비교적 복잡                 |
   |       시간복잡도        |            O(1)             |            O(log n) (heap 구조)            |
   | 시간에 따른 페이지 변화 |            반영             |                 반영 불가                  |

   ![image-20210629145030155](8장 가상메모리.assets/image-20210629145030155-1624945832006.png)

   - LRU 알고리즘 : 1번 삭제, 다른 페이지들에 비해 참조 시점이 오래되었지만 가장 빈번하게 사용되었음, 그러나 LRU 알고리즘은 이러한 사실을 인지하지 못함
   - LFU 알고리즘 : 4번 삭제, 4번 페이지가 지금부터 인기를 얻기 시작할 수 있으나 LFU 알고리즘은 이러한 사실을 인지하지 못함 

6. 클럭 알고리즘 (clock algorithm)

   - 앞의 LFU / LRU 알고리즘은 페이지의 참조 시각 및 참조 횟수를 소프트웨어적으로 유지하고 비교해야 하기 때문에 알고리즘의 운영에 시간적인 오버헤드를 발생시킬 수 있음

   - 클럭 알고리즘은 하드웨어적인 지원을 통해 이와 같은 알고리즘의 운영 오버헤드를 줄인 방식

   - LRU 알고리즘을 근사시킨 방법으로 NUR (Not Used Recently) 혹은 NRU (Not Recently Used) 알고리즘으로도 불림

   - 대부분의 시스템에서 채택된 알고리즘

   - 페이지 프레임들의 참조비트를 순차적으로 조사, 참조비트는 각 프레임마다 하나씩 존재하며 그 프레임 내의 페이지가 참조될 때 하드웨어에 의해 자동세팅됨

     - 참조비트 1 : 최근 사용된 페이지
     - 참조비트 0 : 최근 사용되지 않은 페이지
     - 시곗바늘이 한바퀴 도는 동안 다시 참조되지 않은 페이지를 교체

   - 시곗바늘 한 바퀴 도는 데 소요되는 시간만큼 페이지를 메모리에 유지시켜 둠으로써 페이지 부재율을 줄이도록 설계되었기 때문에 2차 기회 알고리즘 (second chance algorithm)이라고도 부름

     ![image-20210629152242618](8장 가상메모리.assets/image-20210629152242618-1624947764361.png)



## 4. 페이지 프레임의 할당

- 복수의 프로세스가 동시에 수행되는 경우 각 프로세스에 얼마만큼의 메모리 공간을 할당할 것인지 결정하기 위해 효율적인 메모리 할당 방법이 필요
  1. 균등할당 : 모든 프로세스에 페이지 프레임을 균일하게 할당 
  2. 비례할당 : 프로세스의 크기에 비례해 페이지 프레임을 할당
  3. 우선순위 할당  : 프로세스의 우선순위에 따라 페이지 프레임을 다르게 할당, 프로세스 중 당장 CPU에서 실행될 프로세스와 그렇지 않은 프로세스를 구분하여 전자 쪽에 더 많은 페이지 프레임을 할당
- 적어도 일정 수준 이상의 페이지 프레임을 각 프로세스에 할당해야함
- 반복문을 실행중인 프로세스의 경우 반복문을 구성하는 페이지들을 한꺼번에 메모리에 올려놓는 것이 유리
- 이와 같은 종합적인 상황을 고려해 각 프로세스에 할당되는 프레임의 수를 결정할 필요성이 있음



## 5. 전역교체와 지역교체

- 교체할 페이지를 선정할 때 교체 대상이 될 프레임의 범위에 따라 전역교체 (global replacement)와 지역교체(local replacement)로 구분 
  1. 전역교체 : 모든 페이지 프레임이 교체 대상이 될 수 있는 방법, 전체 메모리를 각 프로세스가 공유해서 사용하는 경우 
  2. 지역교체 : 현재 수행 중인 프로세스에게 할당된 프레임 내에서만 교체 대상을 선정할 수 있는 방법, 프로세스마다 페이지 프레임이 미리 할당되어 있을 경우 



## 6. 스레싱 (Thrashing)

- 스레싱 : 부재율이 크게 상승해 CPU 이용률이 급격히 떨어지는 현상

  - 프로세스의 원활한 수행에 필요한 최소한의 page frame 수를 할당받지 못한 경우 발생 
  - Page fault rate이 매우 높아짐
  - CPU utilization이 낮아짐 

- 따라서 MPD (다중 프로그래밍의 정도)를 적정히 조절하는 것이 중요하다

  - MPD가 너무 낮으면 CPU 이용률이 낮아서 준비 큐가 비는 경우가 발생
  - MPD가 너무 높으면 각 프로세스에 필요한 최소한의 page frame을 보장하지 못해 스레싱 발생

  ![image-20210630143206306](8장 가상메모리.assets/image-20210630143206306-1625031127643.png)



1. 워킹셋 알고리즘

   - 지역성 집합 (집중적으로 참조되는 페이지들의 집합)이 메모리에 동시에 올라갈 수 있도록 보장하는 메모리 관리 알고리즘

   - `워킹셋` : 프로세스가 일정시간 동안 원활히 수행되기 위해 한꺼번에 메모리에 올라와 있어야하는 페이지들의 집합

     - 프로세스의 워킹셋을 구성하는 페이지들이 한꺼번에 메모리에 올라갈 수 있는 경우에만 그 프로세스에게 메모리 할당
     - 그렇지 않을 경우 프로세스에게 할당된 페이지 프레임들을 모두 반납시킨 후 그 프로세스의 주소 공간 전체를 디스크로 스왑 아웃 시킴

   - 과거에 사용된 페이지의 히스토리에 근거해서 각 프로세스에 몇개의 page를 할당할지 결정

   - 프로세스가 메모리를 많이 필요로 할 때에는 많이 할당하고 적게 필요로 할 때에는 적게 할당하는 동적 프레임 할당 기능도 수행 

     ![image-20210630145113191](8장 가상메모리.assets/image-20210630145113191-1625032274912.png)

2. 페이지 부재 빈도 알고리즘 (PFF : Page Fault Frequency)

   - 프로세스의 페이지 부재율을 주기적으로 조사하고 이 값에 근거하여 각 프로세스에 할당할 메모리 양을 동적으로 조절하는 알고리즘 
   - page-fault rate의 상한값과 하한값을 둔다
     - Page fault rate이 상한값을 넘으면 frame을 더 할당한다
     - Page fault rate이 하한값 이하이면 할당 frame 수를 줄인다
   - 빈 frame이 없으면 일부 프로세스를 swap out
   - 프레임이 남으면 swap out 된 프로세스에게 프레임을 할당해 MPD를 높인다

   ![image-20210630150712246](8장 가상메모리.assets/image-20210630150712246-1625033233647.png)